# Phase 3: æº–å‚™è³‡æ–™

## æ¦‚è¿°

å°‡åŸå§‹è³‡æ–™è½‰æ›ç‚ºè¨“ç·´æ‰€éœ€çš„ chat formatã€‚

## è³‡æ–™æµç¨‹

```
åŸå§‹è³‡æ–™ â†’ é©—è­‰ â†’ è½‰æ› â†’ åˆ†å‰² â†’ Chat Format
data/raw/    01_validate   02_convert   â†’   data/chat_format/
```

## è³‡æ–™æ ¼å¼

### åŸå§‹æ ¼å¼ (data/raw/)

```jsonl
{"text": "å…¬å¸ç‡Ÿæ”¶å‰µæ–°é«˜", "label": "æ­£é¢"}
{"text": "è‚¡åƒ¹å¤§è·Œ", "label": "è² é¢"}
```

### Chat Format (data/chat_format/)

```jsonl
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯æƒ…æ„Ÿåˆ†æå°ˆå®¶..."},
    {"role": "user", "content": "è«‹åˆ†æï¼šå…¬å¸ç‡Ÿæ”¶å‰µæ–°é«˜"},
    {"role": "assistant", "content": "æ­£é¢"}
  ]
}
```

## æ­¥é©Ÿ

### Step 1: é©—è­‰è³‡æ–™

```bash
python scripts/01_validate_data.py
```

é©—è­‰é …ç›®ï¼š
- JSON æ ¼å¼æ­£ç¢ºæ€§
- å¿…è¦æ¬„ä½å­˜åœ¨
- æ¨™ç±¤å€¼åˆæ³•æ€§
- é¡åˆ¥åˆ†ä½ˆ

è¼¸å‡ºç¯„ä¾‹ï¼š
```
ğŸ“„ data/raw/train.jsonl
   ç¸½ç­†æ•¸: 1000
   é¡åˆ¥åˆ†ä½ˆ: {'æ­£é¢': 350, 'è² é¢': 330, 'ä¸­ç«‹': 320}
   âœ… é©—è­‰é€šé
```

### Step 2: è½‰æ›æ ¼å¼

```bash
python scripts/02_convert_format.py
```

æ ¸å¿ƒé‚è¼¯ï¼š
```python
def convert_to_chat_format(sample):
    return {
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘ï¼š\n\n{sample['text']}"},
            {"role": "assistant", "content": sample['label']}
        ]
    }
```

### Step 3: åˆ†å‰²è³‡æ–™

å»ºè­°æ¯”ä¾‹ï¼š
| è³‡æ–™é›† | æ¯”ä¾‹ | ç”¨é€” |
|--------|------|------|
| Train | 70-80% | è¨“ç·´ |
| Valid | 10-15% | é©—è­‰ï¼ˆèª¿åƒã€early stoppingï¼‰|
| Test | 10-15% | æœ€çµ‚è©•ä¼° |

## Prompt è¨­è¨ˆ

### åˆ†é¡ä»»å‹™

```python
SYSTEM_PROMPT = """ä½ æ˜¯æƒ…æ„Ÿåˆ†æå°ˆå®¶ã€‚è«‹åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘ã€‚

åªèƒ½å›ç­”ä»¥ä¸‹é¡åˆ¥ä¹‹ä¸€ï¼šæ­£é¢ã€è² é¢ã€ä¸­ç«‹

ä¸è¦åŠ å…¥ä»»ä½•è§£é‡‹æˆ–å…¶ä»–æ–‡å­—ã€‚"""

USER_TEMPLATE = """è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘ï¼š

{text}"""
```

### æŠ½å–ä»»å‹™ (NER)

```python
SYSTEM_PROMPT = """ä½ æ˜¯å‘½åå¯¦é«”è­˜åˆ¥å°ˆå®¶ã€‚è«‹è­˜åˆ¥æ–‡æœ¬ä¸­çš„å¯¦é«”ã€‚

å¯¦é«”é¡å‹ï¼š
- PER: äººç‰©
- ORG: çµ„ç¹”
- LOC: åœ°é»

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºã€‚"""

USER_TEMPLATE = """è«‹è­˜åˆ¥ä»¥ä¸‹æ–‡æœ¬ä¸­çš„å¯¦é«”ï¼š

{text}"""

# è¼¸å‡º
ASSISTANT_TEMPLATE = """{"entities": [{"text": "å°ç©é›»", "type": "ORG"}]}"""
```

### ç”Ÿæˆä»»å‹™

```python
SYSTEM_PROMPT = """ä½ æ˜¯å°ˆæ¥­çš„å…¬æ–‡æ’°å¯«åŠ©æ‰‹ã€‚

è«‹å°‡å£èªåŒ–çš„æ–‡å­—è½‰æ›ç‚ºæ­£å¼å…¬æ–‡æ ¼å¼ã€‚"""

USER_TEMPLATE = """è«‹å°‡ä»¥ä¸‹å…§å®¹è½‰æ›ç‚ºå…¬æ–‡æ ¼å¼ï¼š

åŸæ–‡ï¼š{text}
å…¬æ–‡é¡å‹ï¼š{doc_type}
å±¤ç´šï¼š{level}"""
```

## è³‡æ–™å“è³ªæª¢æŸ¥æ¸…å–®

- [ ] é¡åˆ¥åˆ†ä½ˆæ˜¯å¦å¹³è¡¡ï¼Ÿ
- [ ] æ¨™ç±¤æ˜¯å¦ä¸€è‡´ï¼Ÿ
- [ ] æœ‰ç„¡é‡è¤‡æ¨£æœ¬ï¼Ÿ
- [ ] æ–‡æœ¬é•·åº¦åˆ†ä½ˆåˆç†ï¼Ÿ
- [ ] ç‰¹æ®Šå­—å…ƒè™•ç†æ­£ç¢ºï¼Ÿ

## å¸¸è¦‹å•é¡Œ

### é¡åˆ¥ä¸å¹³è¡¡

è¦‹ [troubleshooting/class-imbalance.md](../references/troubleshooting/class-imbalance.md)

### æ¨™ç±¤ä¸ä¸€è‡´

```python
# æ¨™æº–åŒ–æ¨™ç±¤
label_mapping = {
    "positive": "æ­£é¢",
    "æ­£å‘": "æ­£é¢",
    "å¥½": "æ­£é¢",
    # ...
}

def normalize_label(label):
    return label_mapping.get(label.lower(), label)
```

### æ–‡æœ¬éé•·

```python
# æˆªæ–·æˆ–åˆ†æ®µ
MAX_LENGTH = 1000

def truncate_text(text, max_length=MAX_LENGTH):
    if len(text) > max_length:
        return text[:max_length] + "..."
    return text
```

## è³‡æ–™å¢å¼· (å¯é¸)

### éæ¡æ¨£å°‘æ•¸é¡åˆ¥

```python
from collections import Counter

def oversample(data, target_count):
    label_counts = Counter(d['label'] for d in data)
    augmented = list(data)

    for label, count in label_counts.items():
        if count < target_count:
            samples = [d for d in data if d['label'] == label]
            while len([d for d in augmented if d['label'] == label]) < target_count:
                augmented.append(random.choice(samples))

    return augmented
```

### åŒç¾©è©æ›¿æ›

```python
import jieba

def synonym_augment(text, replace_prob=0.1):
    words = list(jieba.cut(text))
    # éš¨æ©Ÿæ›¿æ›éƒ¨åˆ†è©ç‚ºåŒç¾©è©
    return ''.join(augmented_words)
```

## é©—è­‰è½‰æ›çµæœ

```python
# ç¢ºèª chat template æ­£ç¢º
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen3-4B")

with open("data/chat_format/train.jsonl") as f:
    sample = json.loads(f.readline())

prompt = tokenizer.apply_chat_template(
    sample['messages'],
    tokenize=False,
    add_generation_prompt=False
)
print(prompt)
```

## ä¸‹ä¸€æ­¥

è³‡æ–™æº–å‚™å®Œæˆå¾Œé€²å…¥ [Phase 4: è¨“ç·´æ¨¡å‹](04-training.md)

---

*æ›´æ–°: 2026-01*
