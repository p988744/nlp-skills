---
license: apache-2.0
base_model: {{ base_model }}
language: {{ language_code }}
tags:
{% for tag in tags %}
  - {{ tag }}
{% endfor %}
library_name: peft
pipeline_tag: {{ pipeline_tag }}
---

# eland-{{ task_name }}-zh

{{ description }}

## Model Description

- **Base Model**: [{{ base_model }}](https://huggingface.co/{{ base_model }})
- **Training Method**: LoRA ({{ method | upper }})
- **Language**: {{ language }}
- **License**: Apache 2.0

## Performance

| Metric | Score |
|--------|-------|
{% for metric, score in metrics.items() %}
| {{ metric }} | {{ "%.2f%%"|format(score * 100) }} |
{% endfor %}

## Usage

### With PEFT

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# Load base model
base_model = AutoModelForCausalLM.from_pretrained("{{ base_model }}")
tokenizer = AutoTokenizer.from_pretrained("{{ base_model }}")

# Load LoRA adapter
model = PeftModel.from_pretrained(base_model, "{{ hf_org }}/eland-{{ task_name }}-zh")

# Inference
messages = [
    {"role": "system", "content": "{{ system_prompt }}"},
    {"role": "user", "content": "Your input text"}
]

prompt = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    {% if model_family == 'qwen3' %}
    enable_thinking=False,
    {% endif %}
)

inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

## Training Details

| Parameter | Value |
|-----------|-------|
| LoRA Rank | {{ lora_r }} |
| LoRA Alpha | {{ lora_alpha }} |
| Epochs | {{ epochs }} |
| Learning Rate | {{ learning_rate }} |
| Batch Size | {{ batch_size }} |

## Related Models

- [GGUF for Ollama](https://huggingface.co/{{ hf_org }}/eland-{{ task_name }}-zh-gguf)
- [Merged for vLLM](https://huggingface.co/{{ hf_org }}/eland-{{ task_name }}-zh-vllm)

## Citation

If you use this model, please cite:

```bibtex
@misc{eland-{{ task_name }}-zh,
  title={eland-{{ task_name }}-zh},
  author={Eland AI},
  year={2026},
  publisher={HuggingFace}
}
```
